import os
import random
import argparse
import yaml
from tqdm import tqdm

import torch
import torch.nn.functional as F
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models as torchvision_models

from datasets.imagenet import ImageNet
from datasets import build_dataset
from datasets.utils import build_data_loader
import clip
from utils import *
import dino.utils as utils
import itertools
import json
import numpy as np
from PIL import Image
import os.path as osp
from torch.nn import Module
from torchvision.transforms.functional import to_pil_image
from sklearn.decomposition import PCA
from sklearn.manifold import LocallyLinearEmbedding
import scipy.linalg as la

# VAEæ¨¡å—å®šä¹‰
# åŸå§‹VAEæ¨¡å‹ï¼Œä½¿ç”¨BatchNorm
class VAE(Module):
    def __init__(self, input_dim=1024, hidden_dim=512, latent_dim=256):
        super(VAE, self).__init__()
        
        # ç¼–ç å™¨ - ç¡®ä¿ä¸é¢„è®­ç»ƒæ¨¡å‹ç»“æ„ä¸€è‡´
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 512),  # ç¬¬ä¸€å±‚ä»input_dimç»´åº¦åˆ°512
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU()
        )
        
        # å‡å€¼å’Œæ–¹å·®
        self.fc_mu = nn.Linear(512, 256)
        self.fc_var = nn.Linear(512, 256)
        
        # è§£ç å™¨
        self.decoder = nn.Sequential(
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, input_dim)  # ç¡®ä¿è¾“å‡ºç»´åº¦ä¸è¾“å…¥ç»´åº¦ç›¸åŒ
        )
    
    # VAEæŸå¤±å‡½æ•°
def vae_loss(recon_x, x, mean, log_var, target=None, clip_weights=None):
    REC = (recon_x - x).pow(2).sum(1).mean()
    KLD = -0.5 * (1 + log_var - mean.pow(2) - log_var.exp()).sum(dim=1).mean()
    return (REC + 1 * KLD)

# æƒé‡åˆå§‹åŒ–å‡½æ•°ï¼ˆä¿®å¤ç‰ˆï¼Œé¿å…é›¶å…ƒç´ å¼ é‡è­¦å‘Šï¼‰
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Linear') != -1:
        # æ£€æŸ¥æƒé‡æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
        if hasattr(m, 'weight') and m.weight is not None and m.weight.numel() > 0:
            m.weight.data.normal_(0.0, 0.02)
        # æ£€æŸ¥åç½®æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
        if hasattr(m, 'bias') and m.bias is not None and m.bias.numel() > 0:
            m.bias.data.fill_(0)
    elif classname.find('BatchNorm') != -1:
        # æ£€æŸ¥æƒé‡æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
        if hasattr(m, 'weight') and m.weight is not None and m.weight.numel() > 0:
            m.weight.data.normal_(1.0, 0.02)
        # æ£€æŸ¥åç½®æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
        if hasattr(m, 'bias') and m.bias is not None and m.bias.numel() > 0:
            m.bias.data.fill_(0)

# ç¼–ç å™¨
class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(1024, 4096),  # ä¿®æ”¹è¾“å…¥ç»´åº¦ä¸º1024ï¼Œä¸CLIPç‰¹å¾ç»´åº¦åŒ¹é…
            nn.ReLU(),
        )
        self.mean = nn.Linear(4096, 512)
        self.log_var = nn.Linear(4096, 512)
        self.apply(weights_init)
        
    def forward(self, x, a=None):
        # a å‚æ•°æ˜¯å¯é€‰çš„ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬åªä½¿ç”¨ x
        x = self.net(x)
        mean = self.mean(x)
        log_var = self.log_var(x)
        return mean, log_var

# ç”Ÿæˆå™¨
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(512, 4096),  # è¾“å…¥æ˜¯512ç»´çš„æ½œåœ¨ç©ºé—´å‘é‡
            nn.LeakyReLU(0.2),
            nn.Linear(4096, 1024)  # è¾“å‡ºæ”¹ä¸º1024ç»´ï¼Œä¸CLIPç‰¹å¾ç»´åº¦åŒ¹é…
        )
        self.apply(weights_init)
    
    def forward(self, x):
        # ç¡®ä¿è¾“å…¥æ•°æ®ç±»å‹ä¸æ¨¡å‹æƒé‡ä¸€è‡´
        x = x.to(self.net[0].weight.dtype)
        out = self.net(x)
        return out
        
# æ•°æ®æµå½¢å’Œåˆ‡ç©ºé—´æŠ•å½±ç›¸å…³ç±»å’Œå‡½æ•°
class ManifoldProjector:
    """
    æ•°æ®æµå½¢å­¦ä¹ å’Œåˆ‡ç©ºé—´æŠ•å½±ç±»
    """
    def __init__(self, manifold_dim=64, n_neighbors=20):
        self.manifold_dim = manifold_dim
        self.n_neighbors = n_neighbors
        self.pca = None
        self.tangent_basis = None
        self.mean_feature = None
        self.fitted = False
        
    def fit_manifold(self, features):
        """
        ä½¿ç”¨PCAå’Œå±€éƒ¨çº¿æ€§åµŒå…¥æ¥å­¦ä¹ æ•°æ®æµå½¢
        
        Args:
            features: è¾“å…¥ç‰¹å¾å¼ é‡ï¼Œå½¢çŠ¶ä¸º [N, feature_dim]
        """
        print(f"æ­£åœ¨æ‹Ÿåˆæ•°æ®æµå½¢ï¼Œè¾“å…¥ç‰¹å¾å½¢çŠ¶: {features.shape}")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œå¤„ç†
        if isinstance(features, torch.Tensor):
            features_np = features.detach().cpu().numpy()
        else:
            features_np = features
            
        # è®¡ç®—å‡å€¼ç‰¹å¾
        self.mean_feature = np.mean(features_np, axis=0)
        
        # ä½¿ç”¨PCAè¿›è¡Œåˆæ­¥é™ç»´å’Œæ‰¾åˆ°ä¸»è¦å˜åŒ–æ–¹å‘
        try:
            # ç¡®ä¿manifold_dimä¸è¶…è¿‡ç‰¹å¾ç»´åº¦å’Œæ ·æœ¬æ•°é‡
            n_samples, feature_dim = features_np.shape
            effective_manifold_dim = min(self.manifold_dim, feature_dim, n_samples - 1)
            
            if effective_manifold_dim <= 0:
                print(f"âŒ æµå½¢å­¦ä¹ å¤±è´¥ - æœ‰æ•ˆæµå½¢ç»´åº¦å°äºç­‰äº0")
                print(f"   - æ ·æœ¬æ•°é‡: {n_samples}")
                print(f"   - ç‰¹å¾ç»´åº¦: {feature_dim}")
                print(f"   - è¯·æ±‚çš„æµå½¢ç»´åº¦: {self.manifold_dim}")
                self.fitted = False
                return
                
            print(f"ä½¿ç”¨æœ‰æ•ˆæµå½¢ç»´åº¦: {effective_manifold_dim}")
            
            self.pca = PCA(n_components=effective_manifold_dim)
            self.pca.fit(features_np)
            
            # è·å–åˆ‡ç©ºé—´çš„åŸºå‘é‡ï¼ˆPCAçš„ä¸»æˆåˆ†ï¼‰
            self.tangent_basis = self.pca.components_  # shape: [effective_manifold_dim, feature_dim]
            self.manifold_dim = effective_manifold_dim  # æ›´æ–°å®é™…ä½¿ç”¨çš„ç»´åº¦
            
            print(f"âœ… æµå½¢å­¦ä¹ å®Œæˆï¼Œåˆ‡ç©ºé—´ç»´åº¦: {self.tangent_basis.shape}")
            print(f"   - å‰5ä¸ªä¸»æˆåˆ†çš„è§£é‡Šæ–¹å·®æ¯”: {self.pca.explained_variance_ratio_[:5]}")
            print(f"   - ç´¯è®¡è§£é‡Šæ–¹å·®æ¯”: {np.sum(self.pca.explained_variance_ratio_):.4f}")
            self.fitted = True
            
        except Exception as e:
            print(f"âŒ æµå½¢å­¦ä¹ å¤±è´¥ - è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            print(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"   - é”™è¯¯æè¿°: {str(e)}")
            print(f"   - è¾“å…¥ç‰¹å¾å½¢çŠ¶: {features_np.shape}")
            print(f"   - å°è¯•çš„æµå½¢ç»´åº¦: {self.manifold_dim}")
            print(f"   - ç³»ç»Ÿå°†å›é€€åˆ°æ ‡å‡†é«˜æ–¯å™ªå£°æ¨¡å¼")
            self.fitted = False
        
    def project_noise_to_tangent_space(self, noise_features, dalle_features=None, blend_factor=0.7):
        """
        å°†é«˜æ–¯å™ªå£°æŠ•å½±åˆ°æ•°æ®æµå½¢çš„åˆ‡ç©ºé—´
        
        Args:
            noise_features: é«˜æ–¯å™ªå£°ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º [N, feature_dim]
            dalle_features: DALL-Eç”Ÿæˆçš„ç‰¹å¾ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºå¼•å¯¼æŠ•å½±æ–¹å‘
            blend_factor: å™ªå£°å’ŒDALL-Eç‰¹å¾çš„æ··åˆæ¯”ä¾‹
            
        Returns:
            projected_features: æŠ•å½±åˆ°åˆ‡ç©ºé—´çš„ç‰¹å¾
        """
        if not self.fitted:
            print("âŒ æµå½¢æŠ•å½±å¤±è´¥ - æµå½¢å°šæœªæ‹Ÿåˆ")
            print("   - è¯·å…ˆè°ƒç”¨fit_manifold()æ¥å­¦ä¹ æ•°æ®æµå½¢")
            print("   - è¿”å›åŸå§‹å™ªå£°ç‰¹å¾ä½œä¸ºå›é€€")
            return noise_features
            
        try:
            # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
            if isinstance(noise_features, torch.Tensor):
                noise_np = noise_features.detach().cpu().numpy()
            else:
                noise_np = noise_features.copy()
                
            if dalle_features is not None:
                if isinstance(dalle_features, torch.Tensor):
                    dalle_np = dalle_features.detach().cpu().numpy()
                else:
                    dalle_np = dalle_features.copy()
                
                # æ··åˆå™ªå£°å’ŒDALL-Eç‰¹å¾
                mixed_features = blend_factor * noise_np + (1 - blend_factor) * dalle_np
            else:
                mixed_features = noise_np
                
            # ä¸­å¿ƒåŒ–ç‰¹å¾
            centered_features = mixed_features - self.mean_feature
            
            # æŠ•å½±åˆ°åˆ‡ç©ºé—´ï¼šå…ˆæŠ•å½±åˆ°ä¸»æˆåˆ†ç©ºé—´ï¼Œå†é‡æ„
            # æ­¥éª¤1: æŠ•å½±åˆ°åˆ‡ç©ºé—´ï¼ˆé™ç»´ï¼‰
            tangent_coords = np.dot(centered_features, self.tangent_basis.T)  # [N, manifold_dim]
            
            # æ­¥éª¤2: é‡æ„å›åŸå§‹ç©ºé—´ï¼ˆä½†é™åˆ¶åœ¨åˆ‡ç©ºé—´å†…ï¼‰
            projected_centered = np.dot(tangent_coords, self.tangent_basis)  # [N, feature_dim]
            
            # æ­¥éª¤3: åŠ å›å‡å€¼
            projected_features = projected_centered + self.mean_feature
            
            # è½¬æ¢å›pytorchå¼ é‡
            if isinstance(noise_features, torch.Tensor):
                projected_features = torch.tensor(projected_features, 
                                                dtype=noise_features.dtype, 
                                                device=noise_features.device)
                
            return projected_features
            
        except Exception as e:
            print(f"âŒ æµå½¢æŠ•å½±è¿‡ç¨‹å¤±è´¥ - è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            print(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"   - é”™è¯¯æè¿°: {str(e)}")
            print(f"   - å™ªå£°ç‰¹å¾å½¢çŠ¶: {noise_features.shape}")
            if dalle_features is not None:
                print(f"   - DALL-Eç‰¹å¾å½¢çŠ¶: {dalle_features.shape}")
            print(f"   - æ··åˆæ¯”ä¾‹: {blend_factor}")
            print(f"   - åˆ‡ç©ºé—´ç»´åº¦: {self.tangent_basis.shape if hasattr(self, 'tangent_basis') else 'N/A'}")
            print(f"   - è¿”å›åŸå§‹å™ªå£°ç‰¹å¾ä½œä¸ºå›é€€")
            return noise_features
    
    def generate_manifold_noise(self, n_samples, feature_dim, device='cuda', noise_scale=0.1):
        """
        åœ¨æµå½¢åˆ‡ç©ºé—´ä¸­ç”Ÿæˆç»“æ„åŒ–å™ªå£°
        
        Args:
            n_samples: è¦ç”Ÿæˆçš„æ ·æœ¬æ•°é‡
            feature_dim: ç‰¹å¾ç»´åº¦
            device: è®¾å¤‡
            noise_scale: å™ªå£°ç¼©æ”¾å› å­
            
        Returns:
            structured_noise: ç»“æ„åŒ–å™ªå£°ç‰¹å¾
        """
        # æ£€æŸ¥è¾“å…¥å‚æ•°çš„æœ‰æ•ˆæ€§
        if n_samples <= 0 or feature_dim <= 0:
            print(f"âŒ æµå½¢å™ªå£°ç”Ÿæˆå¤±è´¥ - å‚æ•°æ— æ•ˆ:")
            print(f"   - æ ·æœ¬æ•°é‡: {n_samples}")
            print(f"   - ç‰¹å¾ç»´åº¦: {feature_dim}")
            print(f"   - å›é€€åˆ°æœ€å°æœ‰æ•ˆå‚æ•°")
            n_samples = max(1, n_samples)
            feature_dim = max(1, feature_dim)
            
        if not self.fitted:
            print("âš ï¸  æµå½¢å°šæœªæ‹Ÿåˆï¼Œä½¿ç”¨æ ‡å‡†é«˜æ–¯å™ªå£°")
            return torch.randn(n_samples, feature_dim, device=device) * noise_scale
            
        try:
            # åœ¨åˆ‡ç©ºé—´åæ ‡ä¸­ç”Ÿæˆå™ªå£°
            tangent_noise = np.random.randn(n_samples, self.manifold_dim) * noise_scale
            
            # å°†åˆ‡ç©ºé—´å™ªå£°æ˜ å°„åˆ°åŸå§‹ç‰¹å¾ç©ºé—´
            structured_noise = np.dot(tangent_noise, self.tangent_basis)
            
            # æ·»åŠ å‡å€¼ç‰¹å¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if self.mean_feature is not None:
                structured_noise += self.mean_feature
            
            # è½¬æ¢ä¸ºpytorchå¼ é‡
            structured_noise = torch.tensor(structured_noise, 
                                          dtype=torch.float32, 
                                          device=device)
            
            return structured_noise
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæµå½¢å™ªå£°å¤±è´¥ - è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            print(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"   - é”™è¯¯æè¿°: {str(e)}")
            print(f"   - è¯·æ±‚æ ·æœ¬æ•°: {n_samples}")
            print(f"   - ç‰¹å¾ç»´åº¦: {feature_dim}")
            print(f"   - å™ªå£°ç¼©æ”¾: {noise_scale}")
            print(f"   - æµå½¢ç»´åº¦: {self.manifold_dim if hasattr(self, 'manifold_dim') else 'N/A'}")
            print(f"   - åˆ‡ç©ºé—´å½¢çŠ¶: {self.tangent_basis.shape if hasattr(self, 'tangent_basis') else 'N/A'}")
            print(f"   - å›é€€åˆ°æ ‡å‡†é«˜æ–¯å™ªå£°")
            return torch.randn(n_samples, feature_dim, device=device) * noise_scale

def create_dalle_noise_features(dalle_features, noise_ratio=0.3, manifold_projector=None):
    """
    å°†DALL-Eç‰¹å¾è½¬æ¢ä¸ºå¸¦æœ‰ç»“æ„åŒ–å™ªå£°çš„ç‰¹å¾
    
    Args:
        dalle_features: DALL-Eç”Ÿæˆçš„ç‰¹å¾
        noise_ratio: å™ªå£°æ¯”ä¾‹
        manifold_projector: æµå½¢æŠ•å½±å™¨
        
    Returns:
        noisy_features: å¸¦å™ªå£°çš„ç‰¹å¾
    """
    # æ£€æŸ¥è¾“å…¥ç‰¹å¾æ˜¯å¦ä¸ºç©º
    if dalle_features.numel() == 0:
        print("âŒ DALL-Eç‰¹å¾ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå™ªå£°ç‰¹å¾")
        return dalle_features
        
    device = dalle_features.device
    dtype = dalle_features.dtype
    
    # ç”Ÿæˆé«˜æ–¯å™ªå£°
    gaussian_noise = torch.randn_like(dalle_features)
    
    if manifold_projector is not None and manifold_projector.fitted:
        try:
            print(f"ğŸ”„ ä½¿ç”¨æµå½¢æŠ•å½±ç”ŸæˆDALL-Eå™ªå£°ç‰¹å¾...")
            # ä½¿ç”¨æµå½¢æŠ•å½±å™¨ç”Ÿæˆç»“æ„åŒ–å™ªå£°
            structured_noise = manifold_projector.project_noise_to_tangent_space(
                gaussian_noise, 
                dalle_features, 
                blend_factor=noise_ratio
            )
            print(f"âœ… æµå½¢æŠ•å½±æˆåŠŸ")
            return structured_noise.to(dtype)
        except Exception as e:
            print(f"âŒ DALL-Eç‰¹å¾æµå½¢æŠ•å½±å¤±è´¥ - è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            print(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"   - é”™è¯¯æè¿°: {str(e)}")
            print(f"   - DALL-Eç‰¹å¾å½¢çŠ¶: {dalle_features.shape}")
            print(f"   - å™ªå£°æ¯”ä¾‹: {noise_ratio}")
            print(f"   - å›é€€åˆ°ç®€å•åŠ æ€§å™ªå£°")
            # å›é€€åˆ°ç®€å•å™ªå£°
            noisy_features = dalle_features + gaussian_noise * noise_ratio
            return noisy_features
    else:
        print(f"âš ï¸  æµå½¢æŠ•å½±å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•åŠ æ€§å™ªå£°")
        # ç®€å•çš„åŠ æ€§å™ªå£°
        noisy_features = dalle_features + gaussian_noise * noise_ratio
        return noisy_features

# æ—§çš„VAEæ–¹æ³•ï¼Œä¸å†ä½¿ç”¨
def old_vae_methods():
    pass

# è®­ç»ƒVAEæ¨¡å‹å‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«æµå½¢å­¦ä¹ ï¼‰
def train_vae(cfg, clip_model, gpt3_prompt, classnames, template, dalle_features=None, train_loader=None):
    print("\nå¼€å§‹è®­ç»ƒå¢å¼ºç‰ˆVAEæ¨¡å‹ï¼ˆå«æµå½¢å­¦ä¹ ï¼‰...")
    
    vae_cache_dir = os.path.join(cfg['cache_dir'], 'vae_cache')
    os.makedirs(vae_cache_dir, exist_ok=True)
    
    # åˆ›å»ºæµå½¢æŠ•å½±å™¨
    manifold_projector = ManifoldProjector(
        manifold_dim=cfg.get('manifold_dim', 64),
        n_neighbors=cfg.get('n_neighbors', 20)
    )
    
    # åˆ›å»ºç¼–ç å™¨å’Œç”Ÿæˆå™¨
    netE = Encoder().cuda()
    netG = Generator().cuda()
    
    # åˆå§‹åŒ–ä¼˜åŒ–å™¨
    optimizerE = torch.optim.AdamW(netE.parameters(), lr=cfg.get('vae_lr', 0.001))
    optimizerG = torch.optim.AdamW(netG.parameters(), lr=cfg.get('vae_lr', 0.001))
    
    # è·å–CLIPæ–‡æœ¬ç‰¹å¾
    text_features_list = []
    for classname in classnames:
        # ä»gpt3_promptä¸­è·å–è¯¥ç±»åˆ«çš„æç¤ºè¯
        prompt = gpt3_prompt.get(classname, classname)
        # ç¡®ä¿æç¤ºè¯ä¸ä¼šå¤ªé•¿
        if isinstance(prompt, list) and len(prompt) > 0:
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œåªå–ç¬¬ä¸€ä¸ªå…ƒç´ 
            prompt = prompt[0]
        elif isinstance(prompt, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç¡®ä¿é•¿åº¦é€‚ä¸­
            prompt = prompt.split('.')[0] if '.' in prompt else prompt
            
        # åº”ç”¨æ¨¡æ¿å¹¶ç¡®ä¿ä¸è¶…è¿‡CLIPä¸Šä¸‹æ–‡é•¿åº¦
        texts = []
        for t in template:
            formatted_text = t.format(prompt)
            # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œæˆªæ–­å®ƒ
            if len(formatted_text.split()) > 60:  # ç•™å‡ºä¸€äº›ä½™é‡ï¼ŒCLIPé™åˆ¶æ˜¯77ä¸ªtoken
                formatted_text = ' '.join(formatted_text.split()[:60]) + '.'
            texts.append(formatted_text)
            
        try:
            with torch.no_grad():
                text_feature = clip_model.encode_text(clip.tokenize(texts).cuda())
                text_feature = text_feature.mean(dim=0, keepdim=True)
                text_feature /= text_feature.norm(dim=-1, keepdim=True)
            text_features_list.append(text_feature)
        except RuntimeError as e:
            print(f"å¤„ç†ç±»åˆ«'{classname}'æ—¶å‡ºé”™: {e}")
            # ä½¿ç”¨æ›´ç®€å•çš„æç¤ºè¯é‡è¯•
            simple_texts = [f"a photo of a {classname}."]
            with torch.no_grad():
                text_feature = clip_model.encode_text(clip.tokenize(simple_texts).cuda())
                text_feature = text_feature.mean(dim=0, keepdim=True)
                text_feature /= text_feature.norm(dim=-1, keepdim=True)
            text_features_list.append(text_feature)
            print(f"å·²ä½¿ç”¨ç®€åŒ–æç¤ºè¯å¤„ç†ç±»åˆ«'{classname}'")
    
    # å°†ç‰¹å¾åˆ—è¡¨åˆå¹¶æˆä¸€ä¸ªå¼ é‡
    text_features = torch.cat(text_features_list, dim=0)
    
    # å­¦ä¹ æ•°æ®æµå½¢ï¼ˆä½¿ç”¨æ–‡æœ¬ç‰¹å¾ã€çœŸå®å›¾ç‰‡ç‰¹å¾å’ŒDALL-Eç‰¹å¾ï¼‰
    print("å­¦ä¹ æ•°æ®æµå½¢...")
    manifold_features = text_features.clone()
    
    # 1. æå–çœŸå®è®­ç»ƒå›¾ç‰‡çš„CLIPç‰¹å¾ï¼ˆæ”¹è¿›ç‰ˆï¼šç¡®ä¿åªä½¿ç”¨å®é™…è®­ç»ƒæ ·æœ¬ï¼‰
    if train_loader is not None:
        print("æå–çœŸå®è®­ç»ƒå›¾ç‰‡ç‰¹å¾ç”¨äºæµå½¢å­¦ä¹ ...")
        
        # ===== å…³é”®æ”¹è¿›ï¼šè‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ =====
        shots = cfg.get('shots', 0)
        
        if shots == 0:
            print("   0-shoté…ç½®ï¼šè·³è¿‡çœŸå®æ ·æœ¬æå–")
            real_image_features = []
        elif shots <= 16:
            # Few-shotåœºæ™¯ï¼šåªä½¿ç”¨å®é™…è®­ç»ƒé›†ï¼Œä¸é‡å¤é‡‡æ ·
            print(f"   Few-shotæ¨¡å¼ ({shots}-shot)ï¼šä»…ä½¿ç”¨å®é™…è®­ç»ƒæ ·æœ¬ï¼Œé¿å…åˆ†å¸ƒåç§»")
            real_image_features = []
            
            with torch.no_grad():
                for i, (images, _) in enumerate(train_loader):
                    images = images.cuda()
                    batch_features = clip_model.encode_image(images)
                    batch_features /= batch_features.norm(dim=-1, keepdim=True)
                    real_image_features.append(batch_features)
                    # åªéå†ä¸€æ¬¡è®­ç»ƒé›†ï¼Œä¸é‡å¤é‡‡æ ·
            
            if real_image_features:
                real_features_tensor = torch.cat(real_image_features, dim=0)
                actual_samples = len(real_features_tensor)
                print(f"   âœ… è·å–åˆ° {actual_samples} ä¸ªçœŸå®è®­ç»ƒæ ·æœ¬ç‰¹å¾ï¼ˆç²¾ç¡®åŒ¹é…è®­ç»ƒé›†å¤§å°ï¼‰")
                
                # æ•°æ®è´¨é‡æ£€æŸ¥
                expected_samples = shots * len(classnames)
                if actual_samples != expected_samples:
                    print(f"   âš ï¸  æ ·æœ¬æ•°é‡æç¤ºï¼šå®é™… {actual_samples} vs é¢„æœŸ {expected_samples}")
                
                # å°†çœŸå®å›¾ç‰‡ç‰¹å¾åŠ å…¥æµå½¢å­¦ä¹ 
                manifold_features = torch.cat([manifold_features, real_features_tensor], dim=0)
        else:
            # Many-shotåœºæ™¯ï¼šå¯ä»¥é€‚å½“æ‰©å……ï¼Œä½†è¦æ§åˆ¶ä¸Šé™
            max_real_samples = min(cfg.get('real_image_samples', 1000), shots * len(classnames) * 3)
            print(f"   Many-shotæ¨¡å¼ ({shots}-shot)ï¼šé™åˆ¶çœŸå®æ ·æœ¬æ•°ä¸º {max_real_samples}")
            
            real_image_features = []
            sample_count = 0
            
            with torch.no_grad():
                for i, (images, _) in enumerate(train_loader):
                    if sample_count >= max_real_samples:
                        break
                    images = images.cuda()
                    batch_features = clip_model.encode_image(images)
                    batch_features /= batch_features.norm(dim=-1, keepdim=True)
                    real_image_features.append(batch_features)
                    sample_count += len(batch_features)
            
            if real_image_features:
                real_features_tensor = torch.cat(real_image_features, dim=0)[:max_real_samples]
                print(f"   è·å–åˆ° {len(real_features_tensor)} ä¸ªçœŸå®å›¾ç‰‡ç‰¹å¾ç”¨äºæµå½¢å­¦ä¹ ")
                manifold_features = torch.cat([manifold_features, real_features_tensor], dim=0)
    
    # 2. å¦‚æœæä¾›äº†DALL-Eç‰¹å¾ï¼Œä¹ŸåŠ å…¥æµå½¢å­¦ä¹ 
    if dalle_features is not None:
        print(f"æ•´åˆDALL-Eç‰¹å¾åˆ°æµå½¢å­¦ä¹ ä¸­ï¼ŒDALL-Eç‰¹å¾å½¢çŠ¶: {dalle_features.shape}")
        # ç¡®ä¿DALL-Eç‰¹å¾ä¸æ–‡æœ¬ç‰¹å¾ç»´åº¦ä¸€è‡´
        if dalle_features.shape[-1] == text_features.shape[-1]:
            manifold_features = torch.cat([manifold_features, dalle_features], dim=0)
        else:
            print("DALL-Eç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼Œä»…ä½¿ç”¨æ–‡æœ¬ç‰¹å¾å’ŒçœŸå®å›¾ç‰‡ç‰¹å¾è¿›è¡Œæµå½¢å­¦ä¹ ")
    
    # ===== è¯¦ç»†è¯Šæ–­ä¿¡æ¯ =====
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æµå½¢å­¦ä¹ æ•°æ®æºç»Ÿè®¡ (Shots: {cfg.get('shots', 0)})")
    print(f"{'='*60}")
    print(f"æ€»ç‰¹å¾æ•°: {len(manifold_features)}")
    print(f"  â”œâ”€ æ–‡æœ¬ç‰¹å¾ (ç±»åˆ«åŸå‹): {len(text_features)}")
    
    if train_loader is not None and 'real_features_tensor' in locals():
        real_ratio = len(real_features_tensor) / len(manifold_features) * 100
        print(f"  â”œâ”€ çœŸå®è®­ç»ƒæ ·æœ¬: {len(real_features_tensor)} ({real_ratio:.1f}%)")
        if shots > 0:
            print(f"  â”‚   â””â”€ æœŸæœ›æ ·æœ¬æ•°: {shots * len(classnames)} ({shots} shots Ã— {len(classnames)} ç±»)")
    else:
        print(f"  â”œâ”€ çœŸå®è®­ç»ƒæ ·æœ¬: 0 (æœªä½¿ç”¨)")
    
    if dalle_features is not None and dalle_features.shape[-1] == text_features.shape[-1]:
        dalle_ratio = len(dalle_features) / len(manifold_features) * 100
        print(f"  â””â”€ DALL-Eç‰¹å¾: {len(dalle_features)} ({dalle_ratio:.1f}%)")
    else:
        print(f"  â””â”€ DALL-Eç‰¹å¾: 0 (æœªä½¿ç”¨)")
    
    print(f"{'='*60}\n")
    
    # æ‹Ÿåˆæµå½¢
    manifold_projector.fit_manifold(manifold_features)
    
    # ===== æ”¹è¿›ï¼šVAEè®­ç»ƒä½¿ç”¨ä¸æµå½¢å­¦ä¹ ä¸€è‡´çš„ç‰¹å¾ =====
    shots = cfg.get('shots', 0)
    
    if shots == 0:
        # 0-shot: åªä½¿ç”¨æ–‡æœ¬ç‰¹å¾è®­ç»ƒVAEï¼Œä¿æŒçº¯å‡€
        print("VAEè®­ç»ƒç­–ç•¥ï¼š0-shotæ¨¡å¼ï¼Œä»…ä½¿ç”¨æ–‡æœ¬ç‰¹å¾")
        vae_training_features = text_features
    elif shots <= 16:
        # Few-shot: æ··åˆæ–‡æœ¬å’Œå°‘é‡çœŸå®æ ·æœ¬
        print(f"VAEè®­ç»ƒç­–ç•¥ï¼šFew-shotæ¨¡å¼ ({shots}-shot)ï¼Œæ··åˆæ–‡æœ¬+çœŸå®æ ·æœ¬")
        if 'real_features_tensor' in locals() and len(real_image_features) > 0:
            # å¹³è¡¡æ–‡æœ¬å’ŒçœŸå®æ ·æœ¬çš„æ¯”ä¾‹
            vae_training_features = torch.cat([text_features, real_features_tensor], dim=0)
            print(f"   è®­ç»ƒç‰¹å¾: {len(text_features)} æ–‡æœ¬ + {len(real_features_tensor)} çœŸå®æ ·æœ¬")
        else:
            vae_training_features = text_features
            print(f"   è®­ç»ƒç‰¹å¾: {len(text_features)} æ–‡æœ¬ï¼ˆæ— çœŸå®æ ·æœ¬ï¼‰")
    else:
        # Many-shot: ä½¿ç”¨æ›´å¤šæ ·åŒ–çš„ç‰¹å¾
        print(f"VAEè®­ç»ƒç­–ç•¥ï¼šMany-shotæ¨¡å¼ ({shots}-shot)ï¼Œä½¿ç”¨æµå½¢ç‰¹å¾å­é›†")
        # éšæœºé‡‡æ ·æµå½¢ç‰¹å¾çš„å­é›†ç”¨äºè®­ç»ƒ
        max_vae_samples = min(len(manifold_features), len(classnames) * 10)
        indices = torch.randperm(len(manifold_features))[:max_vae_samples]
        vae_training_features = manifold_features[indices]
        print(f"   ä» {len(manifold_features)} ä¸ªæµå½¢ç‰¹å¾ä¸­é‡‡æ · {max_vae_samples} ä¸ª")
    
    # åˆ›å»ºæ ‡ç­¾å’Œæ•°æ®é›†
    labels = torch.arange(len(vae_training_features)).cuda()
    batch_size = min(16, len(vae_training_features))
    
    # å°†ç‰¹å¾å¼ é‡è½¬æ¢ä¸ºæ•°æ®åŠ è½½å™¨
    vae_dataset = torch.utils.data.TensorDataset(vae_training_features, labels)
    vae_dataloader = torch.utils.data.DataLoader(
        vae_dataset, 
        batch_size=batch_size, 
        shuffle=True
    )
    
    print(f"VAEè®­ç»ƒæ•°æ®åŠ è½½å™¨å·²åˆ›å»º: {len(vae_training_features)} æ ·æœ¬, batch_size={batch_size}")
    
    # è®­ç»ƒVAEæ¨¡å‹
    best_loss = float('inf')
    best_state_dict_E = None
    best_state_dict_G = None
    model_path_E = os.path.join(cfg['cache_dir'], f"best_vae_encoder_{cfg['shots']}shots.pt")
    model_path_G = os.path.join(cfg['cache_dir'], f"best_vae_generator_{cfg['shots']}shots.pt")
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(cfg.get('vae_epochs', 100)):
        total_loss = 0
        batch_count = 0
        
        # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        netE.train()
        netG.train()
        
        for feat_batch, target in vae_dataloader:
            batch_count += 1
            
            # ç¡®ä¿è¾“å…¥æ•°æ®ç±»å‹æ­£ç¡®
            feat_batch = feat_batch.float()
            
            # å‰å‘ä¼ æ’­
            optimizerE.zero_grad()
            optimizerG.zero_grad()
            
            # ç¼–ç 
            mean, log_var = netE(feat_batch)
            
            # é‡å‚æ•°åŒ–
            std = torch.exp(0.5 * log_var)
            z = torch.randn_like(std).cuda()
            z = mean + std * z
            
            # ç”Ÿæˆ
            bias = netG(z)
            
            # æŸå¤±è®¡ç®—
            recon_features = bias
            loss = vae_loss(recon_features, feat_batch, mean, log_var)
            
            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            loss.backward()
            optimizerE.step()
            optimizerG.step()
            
            total_loss += loss.item()
        
        avg_loss = total_loss / batch_count if batch_count > 0 else float('inf')
        if epoch % 10 == 0:
            print(f"Epoch {epoch}/{cfg.get('vae_epochs', 100)}, Loss: {avg_loss:.6f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_loss < best_loss:
            best_loss = avg_loss
            best_state_dict_E = netE.state_dict()
            best_state_dict_G = netG.state_dict()
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if best_state_dict_E is not None:
        torch.save(best_state_dict_E, model_path_E)
        torch.save(best_state_dict_G, model_path_G)
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    netE.load_state_dict(torch.load(model_path_E))
    netG.load_state_dict(torch.load(model_path_G))
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    netE.eval()
    netG.eval()
    
    print("VAEæ¨¡å‹è®­ç»ƒå®Œæˆ!")
    return netE, netG, manifold_projector

# ä½¿ç”¨VAEç”Ÿæˆå›¾åƒç‰¹å¾ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«æµå½¢æŠ•å½±ï¼‰
def generate_vae_features(cfg, netE, netG, clip_model, gpt3_prompt, classnames, template, 
                         manifold_projector=None, n_samples=10, use_manifold_noise=True):
    print("\nä½¿ç”¨å¢å¼ºç‰ˆVAEç”Ÿæˆå›¾åƒç‰¹å¾ï¼ˆå«æµå½¢æŠ•å½±ï¼‰...")
    
    vae_cache_dir = os.path.join(cfg['cache_dir'], 'vae_generated')
    os.makedirs(vae_cache_dir, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç”Ÿæˆçš„ç‰¹å¾
    features_path = os.path.join(vae_cache_dir, f"vae_features_{cfg['shots']}shots.pt")
    if os.path.exists(features_path) and not cfg.get('regenerate_vae', False):
        print(f"åŠ è½½å·²æœ‰VAEç”Ÿæˆç‰¹å¾: {features_path}")
        return torch.load(features_path)
    
    # ç¡®ä¿VAEæ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
    netE.eval()
    netG.eval()
    
    # è®¾ç½®é»˜è®¤çš„dtypeä»¥ç¡®ä¿ä¸€è‡´æ€§
    default_dtype = clip_model.dtype
    
    all_features = []
    all_labels = []
    
    # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆn_samplesä¸ªæ ·æœ¬
    for class_idx, classname in enumerate(classnames):
        # ä»gpt3_promptä¸­è·å–è¯¥ç±»åˆ«çš„æç¤ºè¯
        prompt = gpt3_prompt.get(classname, classname)
        # ç¡®ä¿æç¤ºè¯ä¸ä¼šå¤ªé•¿
        if isinstance(prompt, list) and len(prompt) > 0:
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œåªå–ç¬¬ä¸€ä¸ªå…ƒç´ 
            prompt = prompt[0]
        elif isinstance(prompt, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç¡®ä¿é•¿åº¦é€‚ä¸­
            prompt = prompt.split('.')[0] if '.' in prompt else prompt
            
        # åº”ç”¨æ¨¡æ¿å¹¶ç¡®ä¿ä¸è¶…è¿‡CLIPä¸Šä¸‹æ–‡é•¿åº¦
        texts = []
        for t in template:
            formatted_text = t.format(prompt)
            # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œæˆªæ–­å®ƒ
            if len(formatted_text.split()) > 60:  # ç•™å‡ºä¸€äº›ä½™é‡ï¼ŒCLIPé™åˆ¶æ˜¯77ä¸ªtoken
                formatted_text = ' '.join(formatted_text.split()[:60]) + '.'
            texts.append(formatted_text)
            
        try:
            with torch.no_grad():
                # è·å–æ–‡æœ¬ç‰¹å¾
                text_feature = clip_model.encode_text(clip.tokenize(texts).cuda())
                text_feature = text_feature.mean(dim=0, keepdim=True)
                text_feature /= text_feature.norm(dim=-1, keepdim=True)
        except RuntimeError as e:
            print(f"å¤„ç†ç±»åˆ«'{classname}'æ—¶å‡ºé”™: {e}")
            # ä½¿ç”¨æ›´ç®€å•çš„æç¤ºè¯é‡è¯•
            simple_texts = [f"a photo of a {classname}."]
            with torch.no_grad():
                text_feature = clip_model.encode_text(clip.tokenize(simple_texts).cuda())
                text_feature = text_feature.mean(dim=0, keepdim=True)
                text_feature /= text_feature.norm(dim=-1, keepdim=True)
        
        # é€šè¿‡å¢å¼ºç‰ˆVAEç”Ÿæˆç‰¹å¾ï¼ˆå«æµå½¢æŠ•å½±ï¼‰
        with torch.no_grad():
            for i in range(n_samples):
                # ç¼–ç 
                mean, log_var = netE(text_feature.float())
                
                # é‡å‚æ•°åŒ– - ä½¿ç”¨æµå½¢ç»“æ„åŒ–å™ªå£°
                std = torch.exp(0.5 * log_var)
                
                # åœ¨æ½œåœ¨ç©ºé—´ä½¿ç”¨æ ‡å‡†é‡å‚æ•°åŒ–
                standard_noise = torch.randn_like(std)
                z = mean + std * standard_noise
                
                # ç”Ÿæˆç‰¹å¾
                gen_feature = netG(z)
                
                # å¦‚æœå¯ç”¨æµå½¢å™ªå£°ä¸”æœ‰æµå½¢æŠ•å½±å™¨ï¼Œå¯¹ç”Ÿæˆçš„ç‰¹å¾è¿›è¡Œåå¤„ç†
                if use_manifold_noise and manifold_projector is not None and manifold_projector.fitted:
                    try:
                        # åœ¨ç‰¹å¾ç©ºé—´ä¸­ç”Ÿæˆæµå½¢ç»“æ„åŒ–å™ªå£°
                        feature_noise = manifold_projector.generate_manifold_noise(
                            n_samples=1,
                            feature_dim=gen_feature.shape[-1],  # ä½¿ç”¨ç‰¹å¾ç©ºé—´ç»´åº¦ï¼ˆ1024ï¼‰
                            device=gen_feature.device,
                            noise_scale=cfg.get('manifold_noise_scale', 0.1)
                        )
                        
                        # å°†ç”Ÿæˆçš„ç‰¹å¾ä¸æµå½¢å™ªå£°ç»“åˆ
                        noise_ratio = cfg.get('feature_blend_factor', 0.8)
                        enhanced_feature = noise_ratio * gen_feature + (1 - noise_ratio) * feature_noise
                        
                        # é€šè¿‡æµå½¢æŠ•å½±è¿›ä¸€æ­¥ä¼˜åŒ–
                        final_feature = manifold_projector.project_noise_to_tangent_space(
                            enhanced_feature,
                            text_feature,
                            blend_factor=0.9  # ä¸»è¦ä¿æŒå¢å¼ºç‰¹å¾ï¼Œå°‘é‡æ··åˆåŸå§‹æ–‡æœ¬ç‰¹å¾
                        )
                        gen_feature = final_feature
                        
                    except Exception as e:
                        print(f"âŒ VAEæµå½¢å¢å¼ºå¤±è´¥ - è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
                        print(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
                        print(f"   - é”™è¯¯æè¿°: {str(e)}")
                        print(f"   - ç”Ÿæˆç‰¹å¾å½¢çŠ¶: {gen_feature.shape}")
                        print(f"   - æ–‡æœ¬ç‰¹å¾å½¢çŠ¶: {text_feature.shape}")
                        print(f"   - ç±»åˆ«: {classnames[class_idx]}")
                        print(f"   - æ ·æœ¬ç´¢å¼•: {i+1}/{n_samples}")
                        print(f"   - ä½¿ç”¨åŸå§‹ç”Ÿæˆç‰¹å¾")
                        # å¦‚æœæµå½¢å¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç”Ÿæˆçš„ç‰¹å¾
                
                # å½’ä¸€åŒ–
                gen_feature /= gen_feature.norm(dim=-1, keepdim=True)
                
                all_features.append(gen_feature)
                all_labels.append(torch.tensor([class_idx], device='cuda'))
    
    # å°†ç‰¹å¾å’Œæ ‡ç­¾ç»„åˆæˆæ•°æ®é›†
    vae_features = torch.cat(all_features, dim=0)
    vae_labels = torch.cat(all_labels, dim=0)
    
    # ä¿å­˜ç‰¹å¾åˆ°æ–‡ä»¶
    torch.save((vae_features, vae_labels), features_path)
    
    print(f"VAEç”Ÿæˆäº† {len(vae_features)} ä¸ªç‰¹å¾å‘é‡ï¼Œå·²ä¿å­˜åˆ° {features_path}")
    return vae_features, vae_labels

# æ„å»ºVAEç¼“å­˜æ¨¡å‹
def build_vae_cache_model(cfg, clip_model, vae_features, vae_labels):
    print("\næ„å»ºVAEç¼“å­˜æ¨¡å‹...")
    
    # ä½¿ç”¨one-hotç¼–ç æ ‡ç­¾ï¼Œä½†ç¡®ä¿ç»´åº¦ä¸clip/dinoç¼“å­˜ä¸€è‡´
    num_classes = 1000
    vae_cache_values = torch.zeros(len(vae_labels), num_classes).cuda().to(clip_model.dtype)
    for i, label in enumerate(vae_labels):
        label_idx = label.item() if hasattr(label, 'item') else label
        vae_cache_values[i, label_idx] = 1
    
    # å°†ç‰¹å¾è½¬ç½®ï¼Œä½¿å…¶å½¢çŠ¶ä¸clip/dinoç¼“å­˜ä¸€è‡´
    # æ ‡å‡†çš„ç¼“å­˜é”®å½¢çŠ¶åº”è¯¥æ˜¯ [num_classes, feature_dim]ï¼Œè€Œä¸æ˜¯ [feature_dim, num_classes]
    vae_cache_keys = vae_features.to(clip_model.dtype)
    
    print(f"VAEç¼“å­˜æ¨¡å‹æ„å»ºå®Œæˆ: é”®å½¢çŠ¶ {vae_cache_keys.shape}, å€¼å½¢çŠ¶ {vae_cache_values.shape}")
    return vae_cache_keys, vae_cache_values


def get_arguments():
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', dest='config', help='settings of Tip-Adapter in yaml format')
    args = parser.parse_args()

    return args

def run_ensemble_tip_dalle_adapter_F(cfg, 
                            clip_cache_keys, 
                            clip_cache_values, 
                            clip_test_features, 
                            dino_cache_keys, 
                            dino_cache_values, 
                            dino_test_features, 
                            test_labels, 
                            clip_weights, 
                            clip_model, 
                            dino_model, 
                            train_loader_F,
                            dalle_train_loader_F,
                            vae_adapter=None,  # ä½¿ç”¨é€‚é…å™¨å¯¹è±¡è€Œä¸æ˜¯ç¼“å­˜é”®
                            vae_cache_values=None):
    
    # æ‰“å°å„ç¼“å­˜çš„å½¢çŠ¶ä¿¡æ¯ï¼Œä¾¿äºè°ƒè¯•
    print(f"CLIPç¼“å­˜é”®å½¢çŠ¶: {clip_cache_keys.shape}, å€¼å½¢çŠ¶: {clip_cache_values.shape}")
    print(f"DINOç¼“å­˜é”®å½¢çŠ¶: {dino_cache_keys.shape}, å€¼å½¢çŠ¶: {dino_cache_values.shape}")
    if vae_adapter is not None and vae_cache_values is not None:
        print(f"VAEé€‚é…å™¨æƒé‡å½¢çŠ¶: {vae_adapter.weight.shape}, å€¼å½¢çŠ¶: {vae_cache_values.shape}")
    
    # Enable the cached keys to be learnable
    clip_adapter = nn.Linear(clip_cache_keys.shape[0], clip_cache_keys.shape[1], bias=False).to(clip_model.dtype).cuda()
    clip_adapter.weight = nn.Parameter(clip_cache_keys.t())
    dino_adapter = nn.Linear(dino_cache_keys.shape[0], dino_cache_keys.shape[1], bias=False).to(clip_model.dtype).cuda()
    dino_adapter.weight = nn.Parameter(dino_cache_keys.t())
    
    optimizer = torch.optim.AdamW(
        itertools.chain(dino_adapter.parameters(), clip_adapter.parameters()),
        lr=cfg['lr'], 
        eps=1e-4)
    
    # è®¡ç®—æ€»è®­ç»ƒæ­¥æ•°ï¼ˆè€ƒè™‘0-shotæƒ…å†µï¼‰
    total_steps = cfg['train_epoch'] * (
        (len(train_loader_F) if train_loader_F is not None else 0) + 
        len(dalle_train_loader_F)
    )
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, total_steps)
    
    beta, alpha = cfg['init_beta'], cfg['init_alpha']
    best_acc, best_epoch = 0.0, 0

    for train_idx in range(cfg['train_epoch']):
        # Train
        clip_adapter.train()
        dino_adapter.train()
        correct_samples, all_samples = 0, 0
        loss_list = []
        print('Train Epoch: {:} / {:}'.format(train_idx, cfg['train_epoch']))

        # origin image (è·³è¿‡0-shotæƒ…å†µ)
        if train_loader_F is not None:
            for i, (images, target) in enumerate(tqdm(train_loader_F)):
                images, target = images.cuda(), target.cuda()
                with torch.no_grad():
                    clip_image_features = clip_model.encode_image(images)
                    clip_image_features /= clip_image_features.norm(dim=-1, keepdim=True)
                    dino_image_features = dino_model(images)
                    dino_image_features /= dino_image_features.norm(dim=-1, keepdim=True)

                clip_affinity = clip_adapter(clip_image_features)
                clip_cache_logits = ((-1) * (beta - beta * clip_affinity)).exp() @ clip_cache_values
                dino_affinity = dino_adapter(dino_image_features).to(dino_cache_values.dtype)
                dino_cache_logits = ((-1) * (beta - beta * dino_affinity)).exp() @ dino_cache_values
                clip_logits = 100. * clip_image_features @ clip_weights

                # èåˆCLIPå’ŒDINOç‰¹å¾
                cache_logits_list = [clip_cache_logits, dino_cache_logits]
                
                # å¦‚æœæä¾›äº†VAEé€‚é…å™¨å’Œç¼“å­˜å€¼ï¼Œä¹Ÿæ·»åŠ åˆ°èåˆä¸­
                if vae_adapter is not None and vae_cache_values is not None:
                    vae_affinity = vae_adapter(clip_image_features)  # ä½¿ç”¨ä¸“ç”¨çš„VAEé€‚é…å™¨
                    vae_cache_logits = ((-1) * (beta - beta * vae_affinity)).exp() @ vae_cache_values
                    cache_logits_list.append(vae_cache_logits)
                
                cache_logits = logits_fuse(clip_logits, cache_logits_list)
                tip_logits = clip_logits + cache_logits * alpha
                loss = F.cross_entropy(tip_logits, target)

                acc = cls_acc(tip_logits, target)
                correct_samples += acc / 100 * len(tip_logits)
                all_samples += len(tip_logits)
                loss_list.append(loss.item())

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                scheduler.step()
        
        # dalle image
        for i, (images, target) in enumerate(tqdm(dalle_train_loader_F)):
            images, target = images.cuda(), target.cuda()
            with torch.no_grad():
                clip_image_features = clip_model.encode_image(images)
                clip_image_features /= clip_image_features.norm(dim=-1, keepdim=True)
                dino_image_features = dino_model(images)
                dino_image_features /= dino_image_features.norm(dim=-1, keepdim=True)

            clip_affinity = clip_adapter(clip_image_features)
            clip_cache_logits = ((-1) * (beta - beta * clip_affinity)).exp() @ clip_cache_values
            dino_affinity = dino_adapter(dino_image_features).to(dino_cache_values.dtype)
            dino_cache_logits = ((-1) * (beta - beta * dino_affinity)).exp() @ dino_cache_values
            clip_logits = 100. * clip_image_features @ clip_weights

            # èåˆCLIPå’ŒDINOç‰¹å¾
            cache_logits_list = [clip_cache_logits, dino_cache_logits]
            
            # å¦‚æœæä¾›äº†VAEé€‚é…å™¨å’Œç¼“å­˜å€¼ï¼Œä¹Ÿæ·»åŠ åˆ°èåˆä¸­
            if vae_adapter is not None and vae_cache_values is not None:
                vae_affinity = vae_adapter(clip_image_features)  # ä½¿ç”¨ä¸“ç”¨çš„VAEé€‚é…å™¨
                vae_cache_logits = ((-1) * (beta - beta * vae_affinity)).exp() @ vae_cache_values
                cache_logits_list.append(vae_cache_logits)
            
            cache_logits = logits_fuse(clip_logits, cache_logits_list)
            tip_logits = clip_logits + cache_logits * alpha
            loss = F.cross_entropy(tip_logits, target)

            acc = cls_acc(tip_logits, target)
            correct_samples += acc / 100 * len(tip_logits)
            all_samples += len(tip_logits)
            loss_list.append(loss.item())

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            scheduler.step()

        current_lr = scheduler.get_last_lr()[0]
        print('LR: {:.6f}, Acc: {:.4f} ({:}/{:}), Loss: {:.4f}'.format(current_lr, correct_samples / all_samples, correct_samples, all_samples, sum(loss_list)/len(loss_list)))

        # Eval
        clip_adapter.eval()
        dino_adapter.eval()

        clip_affinity = clip_adapter(clip_test_features)
        dino_affinity = dino_adapter(dino_test_features).to(dino_cache_values.dtype)
        clip_cache_logits = ((-1) * (beta - beta * clip_affinity)).exp() @ clip_cache_values
        dino_cache_logits = ((-1) * (beta - beta * dino_affinity)).exp() @ dino_cache_values
        clip_logits = 100. * clip_test_features @ clip_weights
        
        # èåˆCLIPå’ŒDINOç‰¹å¾
        cache_logits_list = [clip_cache_logits, dino_cache_logits]
        
        # å¦‚æœæä¾›äº†VAEé€‚é…å™¨å’Œç¼“å­˜å€¼ï¼Œä¹Ÿæ·»åŠ åˆ°æµ‹è¯•è¯„ä¼°ä¸­
        if vae_adapter is not None and vae_cache_values is not None:
            vae_affinity = vae_adapter(clip_test_features)  # ä½¿ç”¨ä¸“ç”¨çš„VAEé€‚é…å™¨
            vae_cache_logits = ((-1) * (beta - beta * vae_affinity)).exp() @ vae_cache_values
            cache_logits_list.append(vae_cache_logits)
        
        cache_logits = logits_fuse(clip_logits, cache_logits_list)
        tip_logits = clip_logits + cache_logits * alpha
        acc = cls_acc(tip_logits, test_labels)

        print("**** CaFo's test accuracy: {:.2f}. ****\n".format(acc))
        if acc > best_acc:
            best_acc = acc
            best_epoch = train_idx
            torch.save(clip_adapter.weight, cfg['cache_dir'] + "/best_F_clip_adapter_" + str(cfg['shots']) + "shots.pt")
            torch.save(dino_adapter.weight, cfg['cache_dir'] + "/best_F_dino_adapter_" + str(cfg['shots']) + "shots.pt")
    
    clip_adapter.weight = torch.load(cfg['cache_dir'] + "/best_F_clip_adapter_" + str(cfg['shots']) + "shots.pt")
    dino_adapter.weight = torch.load(cfg['cache_dir'] + "/best_F_dino_adapter_" + str(cfg['shots']) + "shots.pt")
    print(f"**** After fine-tuning, CaFo's best test accuracy: {best_acc:.2f}, at epoch: {best_epoch}. ****\n")

    del clip_logits, tip_logits, cache_logits, clip_cache_logits, dino_cache_logits, clip_affinity, dino_affinity 
    # Search Hyperparameters
    # _ = search_hp(cfg, affinity, clip_cache_values, clip_test_features, test_labels, clip_weights, clip_adapter=adapter)
    best_beta, best_alpha = search_ensemble_hp(cfg, clip_cache_keys, clip_cache_values, clip_test_features, dino_cache_keys, dino_cache_values, dino_test_features, test_labels, clip_weights, clip_adapter=clip_adapter, dino_adapter=dino_adapter)
    clip_affinity = clip_adapter(clip_test_features)
    dino_affinity = dino_adapter(dino_test_features).to(dino_cache_values.dtype)
    clip_cache_logits = ((-1) * (best_beta - best_beta * clip_affinity)).exp() @ clip_cache_values
    dino_cache_logits = ((-1) * (best_beta - best_beta * dino_affinity)).exp() @ dino_cache_values
    clip_logits = 100. * clip_test_features @ clip_weights
    
    # èåˆCLIPå’ŒDINOç‰¹å¾
    cache_logits_list = [clip_cache_logits, dino_cache_logits]
    
    # å¦‚æœæä¾›äº†VAEé€‚é…å™¨å’Œç¼“å­˜å€¼ï¼Œä¹Ÿæ·»åŠ åˆ°æœ€ç»ˆè¯„ä¼°ä¸­
    if vae_adapter is not None and vae_cache_values is not None:
        vae_affinity = vae_adapter(clip_test_features)  # ä½¿ç”¨ä¸“ç”¨çš„VAEé€‚é…å™¨
        vae_cache_logits = ((-1) * (best_beta - best_beta * vae_affinity)).exp() @ vae_cache_values
        cache_logits_list.append(vae_cache_logits)
    
    cache_logits = logits_fuse(clip_logits, cache_logits_list)
    tip_logits = clip_logits + cache_logits * best_alpha
    print("save logits!!!!!!!!!!!!!")
    torch.save(tip_logits, cfg['cache_dir'] + "/best_tip_dino_dalle_logits_" + str(cfg['shots']) + "shots.pt")

def main():

    # Load config file
    args = get_arguments()
    assert (os.path.exists(args.config))
    
    cfg = yaml.load(open(args.config, 'r', encoding='utf-8'), Loader=yaml.Loader)

    cache_dir = os.path.join('./caches', cfg['dataset'])
    os.makedirs(cache_dir, exist_ok=True)
    cfg['cache_dir'] = cache_dir

    print("\nRunning configs.")
    print(cfg, "\n")

    # CLIP
    clip_model, preprocess = clip.load(cfg['clip_backbone'])
    clip_model.eval()

    # DINO
    dino_model = torchvision_models.__dict__[cfg['dino_backbone']](num_classes=0)
    dino_model.fc = nn.Identity()
    dino_model.cuda()
    utils.load_pretrained_weights(dino_model, "dino/dino_resnet50_pretrain.pth", "teacher", "vit_small'", 16)
    dino_model.eval()

    # ImageNet dataset
    random.seed(1)  #####åŸå§‹æ˜¯2
    torch.manual_seed(1)
    
    print("Preparing ImageNet dataset.")
    imagenet = ImageNet(cfg['root_path'], cfg['shots'], preprocess)

    test_loader = torch.utils.data.DataLoader(imagenet.test, batch_size=64, num_workers=8, shuffle=False)

    # 0-shotæƒ…å†µä¸‹è®­ç»ƒé›†ä¸ºç©ºï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
    if cfg['shots'] == 0:
        print("âš ï¸  0-shoté…ç½®ï¼šè®­ç»ƒé›†ä¸ºç©ºï¼Œè·³è¿‡è®­ç»ƒæ•°æ®åŠ è½½å™¨åˆ›å»º")
        train_loader_cache = None
        train_loader_F = None
    else:
        train_loader_cache = torch.utils.data.DataLoader(imagenet.train, batch_size=256, num_workers=8, shuffle=False)
        train_loader_F = torch.utils.data.DataLoader(imagenet.train, batch_size=256, num_workers=8, shuffle=True)

    dalle_dataset = build_dataset(cfg['dalle_dataset'], cfg['root_path'], cfg['dalle_shots'])
    train_tranform = transforms.Compose([
        transforms.RandomResizedCrop(size=224, scale=(0.5, 1), interpolation=transforms.InterpolationMode.BICUBIC),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))
    ])
    dalle_train_loader_cache = build_data_loader(data_source=dalle_dataset.train_x, batch_size=256, tfm=train_tranform, is_train=True, shuffle=False)
    dalle_train_loader_F = build_data_loader(data_source=dalle_dataset.train_x, batch_size=256, tfm=train_tranform, is_train=True, shuffle=True)
    
    with open(cfg['gpt3_prompt_file']) as f:
        gpt3_prompt = json.load(f)

    # Textual features
    print("Getting textual features as CLIP's classifier.")
    clip_weights = gpt_clip_classifier(imagenet.classnames, gpt3_prompt, clip_model, imagenet.template)
    
    # è·å–DALL-Eå›¾åƒç‰¹å¾ç”¨äºæµå½¢å­¦ä¹ 
    print("æå–DALL-Eå›¾åƒç‰¹å¾ç”¨äºæµå½¢å­¦ä¹ ...")
    dalle_clip_features = []
    sample_count = 0
    max_samples = cfg.get('manifold_samples', 500)  # é™åˆ¶æ ·æœ¬æ•°é‡ä»¥å‡å°‘è®¡ç®—å¼€é”€
    
    for i, (images, _) in enumerate(tqdm(dalle_train_loader_cache)):
        if sample_count >= max_samples:
            break
        images = images.cuda()
        with torch.no_grad():
            batch_features = clip_model.encode_image(images)
            batch_features /= batch_features.norm(dim=-1, keepdim=True)
            dalle_clip_features.append(batch_features)
            sample_count += len(batch_features)
    
    if dalle_clip_features:
        dalle_features_tensor = torch.cat(dalle_clip_features, dim=0)[:max_samples]
        print(f"è·å–åˆ° {len(dalle_features_tensor)} ä¸ªDALL-Eç‰¹å¾ç”¨äºæµå½¢å­¦ä¹ ")
    else:
        dalle_features_tensor = None
        print("æœªè·å–åˆ°DALL-Eç‰¹å¾ï¼Œå°†ä»…ä½¿ç”¨æ–‡æœ¬ç‰¹å¾è¿›è¡Œæµå½¢å­¦ä¹ ")
    
    # è®­ç»ƒå¢å¼ºç‰ˆVAEæ¨¡å‹ - ç¼–ç å™¨ã€ç”Ÿæˆå™¨å’Œæµå½¢æŠ•å½±å™¨
    netE, netG, manifold_projector = train_vae(
        cfg, clip_model, gpt3_prompt, imagenet.classnames, imagenet.template, 
        dalle_features_tensor, train_loader_cache
    )
    
    # ä½¿ç”¨å¢å¼ºç‰ˆVAEç”Ÿæˆç‰¹å¾
    vae_features, vae_labels = generate_vae_features(cfg, netE, netG, clip_model, gpt3_prompt, 
                                                   imagenet.classnames, imagenet.template, 
                                                   manifold_projector, 
                                                   n_samples=cfg.get('vae_samples', 10),
                                                   use_manifold_noise=cfg.get('use_manifold_noise', True))
    
    # æ„å»ºVAEç¼“å­˜æ¨¡å‹
    vae_cache_keys, vae_cache_values = build_vae_cache_model(cfg, clip_model, vae_features, vae_labels)

    # Construct the cache model by few-shot training set
    print("\nConstructing cache model by few-shot visual features and labels.")
    
    # ===== 0-Shotç‰¹æ®Šå¤„ç†ï¼šä¸ä½¿ç”¨çœŸå®æ ·æœ¬ç¼“å­˜ =====
    if cfg['shots'] == 0:
        print("\nâš ï¸  æ£€æµ‹åˆ°0-shoté…ç½®ï¼Œå°†ä¸ä½¿ç”¨çœŸå®æ ·æœ¬ç¼“å­˜")
        # è·å–ç±»åˆ«æ•°é‡
        num_classes = len(imagenet.classnames)
        
        # åˆ›å»ºç©ºçš„ç¼“å­˜å¼ é‡
        # CLIP RN50ç‰¹å¾ç»´åº¦: 1024, DINO ResNet50ç‰¹å¾ç»´åº¦: 2048
        clip_cache_keys = torch.zeros(1024, 0, dtype=torch.float16).cuda()
        clip_cache_values = torch.zeros(0, num_classes, dtype=torch.float16).cuda()
        dino_cache_keys = torch.zeros(2048, 0, dtype=torch.float16).cuda()
        dino_cache_values = torch.zeros(0, num_classes, dtype=torch.float16).cuda()
        
        print(f"   åˆ›å»ºç©ºç¼“å­˜: CLIP keys {clip_cache_keys.shape}, values {clip_cache_values.shape}")
        print(f"              DINO keys {dino_cache_keys.shape}, values {dino_cache_values.shape}")
    else:
        # æ­£å¸¸çš„ç¼“å­˜åŠ è½½æµç¨‹ï¼ˆé0-shotï¼‰
        print("\nConstructing CLIP cache model.")
        clip_cache_keys, clip_cache_values = build_clip_cache_model(cfg, clip_model, train_loader_cache)
        print("\nConstructing DINO cache model.")
        dino_cache_keys, dino_cache_values = build_dino_cache_model(cfg, dino_model, train_loader_cache)

    print("\nConstructing cache model by dalle image.")
    print("\nConstructing CLIP cache model.")
    clip_dalle_cache_keys, clip_dalle_cache_values = build_clip_dalle_cache_model(cfg, clip_model, dalle_train_loader_cache)
    print("\nConstructing DINO cache model.")
    dino_dalle_cache_keys, dino_dalle_cache_values = build_dino_dalle_cache_model(cfg, dino_model, dalle_train_loader_cache)

    # Pre-load test features
    print("\nLoading visual features and labels from test set.")
    print("\nLoading CLIP feature.")
    test_clip_features, test_labels = pre_CLIP_load_features(cfg, "test", clip_model, test_loader)
    print("\nLoading DINO feature.")
    test_dino_features, test_labels = pre_DINO_load_features(cfg, "test", dino_model, test_loader)
    
    # ------------------------------------------ Tip-Adapter-F ------------------------------------------
   
    # åˆ›å»ºä¸“ç”¨VAEé€‚é…å™¨ï¼Œé¿å…ä½¿ç”¨CLIPé€‚é…å™¨
    # ä¸ºæ­¤ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„é€‚é…å™¨ï¼Œæ³¨æ„è¾“å…¥å’Œè¾“å‡ºç»´åº¦
    print("åˆ›å»ºä¸“ç”¨VAEé€‚é…å™¨...")
    print(f"VAEç¼“å­˜é”®åŸå§‹å½¢çŠ¶: {vae_cache_keys.shape}")
    # é€‚é…å™¨è¾“å…¥ç»´åº¦ä¸ºç‰¹å¾ç»´åº¦(1024)ï¼Œè¾“å‡ºç»´åº¦ä¸ºæ ·æœ¬æ•°é‡
    vae_adapter = nn.Linear(1024, vae_cache_values.shape[0], bias=False).cuda().to(clip_model.dtype)
    # åˆå§‹åŒ–æƒé‡ï¼Œä¸éœ€è¦è½¬ç½®ï¼Œå› ä¸ºLinearå±‚ä¼šåœ¨å†…éƒ¨è¿›è¡Œè½¬ç½®
    vae_adapter.weight.data.copy_(vae_cache_keys)
    run_ensemble_tip_dalle_adapter_F(cfg, 
                            torch.cat((clip_cache_keys, clip_dalle_cache_keys), dim=1),
                            torch.cat((clip_cache_values, clip_dalle_cache_values), dim=0), 
                            test_clip_features, 
                            torch.cat((dino_cache_keys, dino_dalle_cache_keys), dim=1), 
                            torch.cat((dino_cache_values, dino_dalle_cache_values), dim=0), 
                            test_dino_features, 
                            test_labels, 
                            clip_weights, 
                            clip_model, 
                            dino_model, 
                            train_loader_F,
                            dalle_train_loader_F,
                            vae_adapter,  # ä¼ é€’é€‚é…å™¨å¯¹è±¡è€Œä¸æ˜¯ç¼“å­˜é”®
                            vae_cache_values)

if __name__ == '__main__':
    main()